{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neuron:\n",
    "    def __init__(self, n_inputs=2, activation='tanh'):\n",
    "        self.w = np.random.randn(n_inputs) * 0.1\n",
    "        self.b = np.random.randn() * 0.1\n",
    "        self.activation_type = activation\n",
    "        self.gradient = 0\n",
    "        self.w_gradients = np.zeros(n_inputs)\n",
    "        self.output = None\n",
    "        self.inputs = None\n",
    "\n",
    "    def activation(self, n):\n",
    "        if self.activation_type == 'sigmoid':\n",
    "            return 1 / (1 + np.exp(-n))\n",
    "        elif self.activation_type == 'tanh':\n",
    "            return np.tanh(n)\n",
    "\n",
    "    def activation_derivative(self):\n",
    "        if self.activation_type == 'sigmoid':\n",
    "            return self.output * (1 - self.output)\n",
    "        elif self.activation_type == 'tanh':\n",
    "            return 1 - self.output ** 2\n",
    "        \n",
    "    def compute_gradients(self, upstream_gradient):\n",
    "        self.gradient = upstream_gradient * self.activation_derivative()\n",
    "        self.w_gradients = self.gradient * self.inputs\n",
    "\n",
    "    def update_parameters(self, learning_rate):\n",
    "        self.w -= learning_rate * self.w_gradients\n",
    "        self.b -= learning_rate * self.gradient\n",
    "\n",
    "    def forward(self, X):\n",
    "        output = self.activation(np.dot(self.w, X) + self.b)\n",
    "        self.inputs, self.output = X, output\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_layer(neurons, inputs):\n",
    "    return np.array([neuron.forward(inputs) for neuron in neurons])\n",
    "\n",
    "\n",
    "class InputLayer:\n",
    "    def __init__(self, n_inputs, activation='tanh'):\n",
    "        self.neurons = [Neuron(n_inputs, activation) for _ in range(n_inputs)]\n",
    "\n",
    "    def forward(self, X):\n",
    "        return forward_layer(self.neurons, X)\n",
    "    \n",
    "    \n",
    "class HiddenLayers:\n",
    "    def __init__(self, prev_layer, height, depth, activation='tanh'):\n",
    "        self.depth =  depth\n",
    "        self.layers = [[Neuron(len(prev_layer.neurons), activation) for _ in range(height)]] + [[Neuron(height, activation) for _ in range(height)] for _ in range(depth - 1)]\n",
    "\n",
    "    def forward(self, inputs, layer=0):\n",
    "        if layer == self.depth: return inputs\n",
    "        return self.forward(\n",
    "            forward_layer(self.layers[layer], inputs),\n",
    "            layer + 1\n",
    "        )\n",
    "\n",
    "\n",
    "class OutputLayer:\n",
    "    def __init__(self, prev_layer, height=1, activation='tanh'):\n",
    "        self.neurons = [Neuron(len(prev_layer.layers[-1]), activation) for _ in range(height)]\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        return forward_layer(self.neurons, inputs)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, input_layer, hidden_layers, output_layer, loss='binary_cross_entropy'):\n",
    "        self.input_layer = input_layer\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.output_layer = output_layer\n",
    "        self.loss = loss\n",
    "\n",
    "    def calculate_loss(self, prediction, y):\n",
    "        if self.loss == 'binary_cross_entropy':\n",
    "            return -y * np.log(prediction) - (1 - y) * np.log(1 - prediction)\n",
    "    \n",
    "    def loss_derivative(self, prediction, y):\n",
    "        if self.loss == 'binary_cross_entropy':\n",
    "            return -y / prediction + (1 - y) / (1 - prediction)\n",
    "\n",
    "    def backpropagation(self, y, predictions, learning_rate):\n",
    "            \n",
    "         # Output layer\n",
    "        for neuron, prediction in zip(self.output_layer.neurons, predictions):\n",
    "            neuron.compute_gradients(self.loss_derivative(prediction, y))\n",
    "            neuron.update_parameters(learning_rate)\n",
    "\n",
    "        # Hidden layers\n",
    "        for layer_idx in reversed(range(self.hidden_layers.depth)):\n",
    "            prev_layer = self.output_layer.neurons if layer_idx == self.hidden_layers.depth - 1 else self.hidden_layers.layers[layer_idx + 1]\n",
    "            for neuron_idx, neuron in enumerate(self.hidden_layers.layers[layer_idx]):\n",
    "                prev_layer_gradient = sum([prev_neuron.gradient * prev_neuron.w[neuron_idx] for prev_neuron in prev_layer])\n",
    "                neuron.compute_gradients(prev_layer_gradient)\n",
    "                neuron.update_parameters(learning_rate)\n",
    "\n",
    "        # Input layer\n",
    "        for neuron_idx, neuron in enumerate(self.input_layer.neurons):\n",
    "            prev_layer_gradient = sum([hidden_neuron.gradient * hidden_neuron.w[neuron_idx] for hidden_neuron in self.hidden_layers.layers[0]])\n",
    "            neuron.compute_gradients(prev_layer_gradient)\n",
    "            neuron.update_parameters(learning_rate)\n",
    "\n",
    "\n",
    "    def train(self, X, y, epochs=10, learning_rate=0.05):\n",
    "        for epoch in range(epochs):\n",
    "            losses = np.array([])\n",
    "            for Xi, yi in zip(X, y):\n",
    "                predictions, loss = self.forward_pass(Xi, yi)\n",
    "                losses = np.append(losses, loss)\n",
    "                self.backpropagation(yi, predictions, learning_rate)\n",
    "            if epoch < 10 or epoch % 10 == 0:\n",
    "                print(f\"Epoch: {epoch}, Loss: {losses.mean()}\")\n",
    "\n",
    "    def forward_pass(self, X, y=None):\n",
    "        input_layer_output = self.input_layer.forward(X)\n",
    "        hidden_layers_output = self.hidden_layers.forward(input_layer_output)\n",
    "        predictions = self.output_layer.forward(hidden_layers_output)\n",
    "        loss = [self.calculate_loss(prediction, y) for prediction in predictions] if y is not None else None\n",
    "        return predictions, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 0.6935038073829864\n",
      "Epoch: 1, Loss: 0.682228372143825\n",
      "Epoch: 2, Loss: 0.6792360491307443\n",
      "Epoch: 3, Loss: 0.6784435873018451\n",
      "Epoch: 4, Loss: 0.678233997846165\n",
      "Epoch: 5, Loss: 0.6781773480222354\n",
      "Epoch: 6, Loss: 0.678159872092369\n",
      "Epoch: 7, Loss: 0.67815188752002\n",
      "Epoch: 8, Loss: 0.678145873855822\n",
      "Epoch: 9, Loss: 0.678140023647277\n",
      "Epoch: 10, Loss: 0.6781339307497295\n",
      "Epoch: 20, Loss: 0.6780432440526627\n",
      "Epoch: 30, Loss: 0.6778339907334732\n",
      "Epoch: 40, Loss: 0.6771653057950974\n",
      "Epoch: 50, Loss: 0.6722102592699776\n",
      "Epoch: 60, Loss: 0.4340017134790014\n",
      "Epoch: 70, Loss: 0.31205629183914224\n",
      "Epoch: 80, Loss: 0.35930950996452365\n",
      "Epoch: 90, Loss: 0.2519430011993509\n",
      "Epoch: 100, Loss: 0.36748206780815224\n",
      "Epoch: 110, Loss: 0.1838500288244871\n",
      "Epoch: 120, Loss: 0.20494084986303596\n",
      "Epoch: 130, Loss: 0.010106177593082273\n",
      "Epoch: 140, Loss: 0.005295567953588696\n"
     ]
    }
   ],
   "source": [
    "input_layer = InputLayer(n_inputs=2, activation='tanh')\n",
    "hidden_layers = HiddenLayers(prev_layer=input_layer, height=3, depth=2, activation='tanh')\n",
    "output_layer = OutputLayer(prev_layer=hidden_layers, activation='sigmoid')\n",
    "\n",
    "model = NeuralNetwork(input_layer, hidden_layers, output_layer)\n",
    "\n",
    "df = pd.read_csv('data/creatures.csv')\n",
    "X, y = df[['height', 'color']].to_numpy(), df['species'].to_numpy()\n",
    "\n",
    "model.train(X, y, 150)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
